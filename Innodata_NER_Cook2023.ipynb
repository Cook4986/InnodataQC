{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2beff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes Innodata transcriptions (.csv or .txt) and returns named entities and associated dataframe\n",
    "##Matt Cook - 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declarations + I/O\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "#I/O\n",
    "target = \"xxx/Volumes/Trade Statistics/Transcriptions\" #Innodata transcriptions \n",
    "namedEntities = \"xxx/Volumes/Trade Statistics/NER\" #Working directory\n",
    "entities = []\n",
    "tableOut = \"xxx/Volumes/Trade Statistics/NER/NER.csv\"#Entities CSV\n",
    "\n",
    "#NLP Config\n",
    "model = \"en_core_web_lg\"\n",
    "nlp = spacy.load(model)\n",
    "nlp.max_length = 100000000\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "labels = [\"PRODUCT\",\"EVENT\",\"FAC\",\"LOC\",\"NORP\",\"GPE\",\"LAW\",\"PERSON\",\"ORG\",\"LANGUAGE\"] \n",
    "\n",
    "#custom stopwords\n",
    "ignore = ['Tls', 'Hk. Tts','Hk.Tts.m.c.c', 'Tts', '&c', 'Hk.Tts','Äî']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify and export named entities for all .txt files in target directory\n",
    "for path in sorted(Path(target + \"/txt\").rglob('*.txt')):\n",
    "    if os.path.getsize(path) > 7:\n",
    "        absolute = (str(path.parent) + \"/\" + path.name)\n",
    "        with open(absolute, \"r\", encoding='utf-8-sig') as transcription:#absolute path for images\n",
    "            iliad = transcription.read()\n",
    "            document = nlp(iliad)\n",
    "            for entity in document.ents:\n",
    "                if (entity.label_ in labels) & (entity.text[0].isdigit() == False) & (entity.text not in ignore):\n",
    "                    entities.append(str(entity.text))\n",
    "                    nerPath = namedEntities + \"/txt/\" + str(path.stem) + \"_txt.txt\"\n",
    "                    with open(nerPath, 'w') as file:\n",
    "                        file.write(str(entities)) \n",
    "                        file.close()\n",
    "        print(\"The following entities have been added to \" + nerPath + \":\")\n",
    "        print(\"entities: \" + str(entities))\n",
    "        print(\"\\n\")\n",
    "    entities.clear()\n",
    "                            \n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify and export named entities for all .csv files in target directory\n",
    "for path in sorted(Path(target + \"/csv\").rglob('*.csv')):\n",
    "    if os.path.getsize(path) > 7:\n",
    "        absolute = (str(path.parent) + \"/\" + path.name)\n",
    "        with open(absolute, \"r\", encoding='utf-8-sig') as transcription:#absolute path for images\n",
    "            iliad = transcription.read()\n",
    "            document = nlp(iliad)\n",
    "            for entity in document.ents:\n",
    "                if (entity.label_ in labels) & (entity.text[0].isdigit() == False) & ('\"' not in entity.text) & (entity.text not in ignore):\n",
    "                    entities.append(entity.text)\n",
    "                    nerPath = namedEntities + \"/csv/\" + str(path.stem) + \"_csv.txt\"\n",
    "                    with open(nerPath, 'w') as file:\n",
    "                        file.write(str(entities)) \n",
    "                        file.close()\n",
    "        print(\"The following entities have been added to \" + nerPath + \":\")\n",
    "        print(\"entities: \" + str(entities))\n",
    "        print(\"\\n\")\n",
    "        entities.clear()\n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with input filename, NER output path, and entities\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#cross-check that DRS FILE-OSN values exist in target directory and add matches to pathsOut + dataframe\n",
    "for path in sorted(Path(namedEntities).rglob('*.txt')):\n",
    "    absolute = (str(path.parent) + \"/\" + path.name)\n",
    "    with open(absolute, \"r\",encoding='utf-8-sig') as text:\n",
    "        entities = text.read()\n",
    "        entities = entities.strip(\"][\")\n",
    "        entities = entities.replace(\"'\",\"\")\n",
    "        entities = entities.replace(\"Äî\",\"\")\n",
    "        entities = entities.replace(\"\\n\",\"\")\n",
    "        print(path.name + \": \" + str(entities) + \"\\n\")\n",
    "    df = df.append({'FILENAME':path.stem,'ENTITIES':entities}, ignore_index=True) #append data frame  \n",
    "    \n",
    "#create new lookup table from dataframe\n",
    "with open(tableOut, mode = 'a') as f:\n",
    "    df.to_csv(f,index=False) #append tableOut with FILENAME and ENTITIES values\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"lookup table created for named entity collection\")\n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a707742",
   "metadata": {},
   "outputs": [],
   "source": [
    "##strip specific list characters? (e.g. \"[]\")\n",
    "###numerals? (regex pattern = r'[0-9]') or .isalpha()\n",
    "##customize stopwords? (e.g. \"T1s\")\n",
    "#Relevant entity labels? (e.g. \"PERSON\")\n",
    "#dataframe append deprecated? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
